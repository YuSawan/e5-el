--eval_strategy epoch
--per_device_train_batch_size 8
--per_device_eval_batch_size 32
--learning_rate 2e-5
--weight_decay 0.01
--optim adamw_hf
--adam_beta1 0.9
--adam_beta2 0.98
--adam_epsilon 1e-6
--max_grad_norm 0.0
--num_train_epochs 5
--lr_scheduler_type linear
--warmup_ratio 0.06
--log_level info
--logging_strategy epoch
--logging_steps 10
--remove_unused_columns False
--save_strategy epoch
--metric_for_best_model loss
--report_to wandb
--load_best_model_at_end
--eval_on_start
